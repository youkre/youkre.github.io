---
title: "第4章 朴素贝叶斯、文本分类与情感分析"
date: "2025-09-17T08:00:00+08:00"
---

**分类（Classification）** 是人类与机器智能的核心所在。判断感官接收到的是哪个字母、单词或图像，识别面孔或声音，分拣邮件，给作业评分——这些都属于为输入信息分配类别的任务。作家豪尔赫·路易斯·博尔赫斯（Jorge Luis Borges, 1964）曾以寓言的方式突显了这一任务的潜在挑战，他想象将动物分为以下类别：

* (a) 属于皇帝的动物，
* (b) 经过防腐处理的动物，
* (c) 受过训练的动物，
* (d) 吃奶的小猪，
* (e) 美人鱼，
* (f) 传说中的动物，
* (g) 流浪狗，
* (h) 被包含在此分类中的动物，
* (i) 像疯了一样发抖的动物，
* (j) 数不清的动物，
* (k) 用极细的骆驼毛笔画出的动物，
* (l) 其他动物，
* (m) 刚刚打碎花瓶的动物，
* (n) 从远处看像苍蝇的动物。

许多语言处理任务都涉及分类，不过幸运的是，我们的分类标准远比博尔赫斯的分类清晰明确。在本章中，我们将介绍**朴素贝叶斯（naive Bayes）**算法，并将其应用于**文本分类（text categorization）**任务，即为整篇文本或文档分配一个标签或类别。

我们将重点关注一种常见的文本分类任务——**情感分析（sentiment analysis）**，即提取文本中作者对某个对象所表达的**情感（sentiment）**，也就是其正面或负面的态度。网络上的电影、书籍或产品评论表达了作者对这些产品的看法，而社论或政治性文本则表达了对某位候选人或政治行动的情感倾向。因此，提取消费者或公众的情感在市场营销到政治等众多领域都具有重要意义。

情感分析最简单的形式是一种二分类任务，而评论中的词语为此提供了极佳的线索。例如，考虑以下从电影和餐厅评论中提取的正负例句。像 *great*（很棒）、*richly*（丰富地）、*awesome*（令人惊叹的）这类词，以及 *pathetic*（可悲的）、*awful*（糟糕的）、*ridiculously*（荒谬地）这类词，都是非常有信息量的线索：

* `+` ...古怪的角色和深刻的讽刺，还有一些精彩的剧情转折
* `−` 这太可悲了。最糟糕的是拳击场景……
* `+` ...美味的焦糖酱和香甜的烤杏仁。我太爱这个地方了！
* `−` ...糟糕的披萨，而且价格高得离谱……

**垃圾邮件检测（Spam detection）** 是另一个重要的商业应用，即二分类任务，将电子邮件归类为“垃圾邮件”或“非垃圾邮件”。许多词汇和其他特征可用于执行此类分类。例如，如果一封邮件包含“在线药品”（online pharmaceutical）、“完全免费”（WITHOUT ANY COST）或“亲爱的获奖者”（Dear Winner）等短语，你有理由对其保持怀疑。

对一篇文本，我们可能还想了解的另一种信息是其使用的语言。例如，社交媒体上的文本可能使用多种语言，我们需要据此采用不同的处理方式。因此，**语言识别（language id）** 是大多数语言处理流程的第一步。类似的文本分类任务，如**作者归属（authorship attribution）** —— 确定文本的作者 —— 在数字人文、社会科学和司法语言学领域也具有重要价值。

最后，文本分类中最古老的任务之一是为文本分配图书馆主题类别或主题标签。判断一篇研究论文是关于流行病学还是胚胎学，是信息检索的重要组成部分。目前存在多种主题分类体系，例如医学主题词表（MeSH, Medical Subject Headings）。事实上，正如我们将看到的，朴素贝叶斯算法最初正是在1961年为解决主题分类任务而发明的（Maron, 1961）。

分类在文档以下的层级任务中也同样至关重要。我们之前已经遇到过句号消歧（判断一个句点是句子的结束还是单词的一部分）和词例切分（判断一个字符是否应作为词边界）。甚至语言建模也可以被视为一种分类：每个词都可以看作一个类别，因此预测下一个词的过程，实际上就是将当前上下文分类到各个可能的后续词类别中。词性标注器（第17章）则将句子中每个词的出现归类为名词、动词等。

分类的目标是：获取单个观测样本，提取一些有用的特征，并据此将其划分到一组离散类别中的某一个。对文本进行分类的一种方法是使用人工编写的规则。手工制定的基于规则的分类器可以成为语言处理领域最先进系统的一部分组件。然而，规则往往较为脆弱，因为随着情况或数据随时间变化，规则可能失效；而且对于某些任务，人类本身未必擅长制定出有效的规则。

在语言处理中，文本分类最常见的方法是通过**监督式机器学习（supervised machine learning）**，这也是本章的主题。在监督学习中，我们拥有一组输入观测数据集，其中每一个都关联着正确的输出结果（即“监督信号”）。算法的目标是学习如何从一个新的观测样本映射到正确的输出。

形式上，监督分类的任务是：给定一个输入 $x$ 和一组固定的输出类别 $Y = \{y_1, y_2, ..., y_M\}$，返回一个预测类别 $y \in Y$。在文本分类中，我们有时用 $c$（代表“class”，类别）代替 $y$ 作为输出变量，用 $d$（代表“document”，文档）代替 $x$ 作为输入变量。在监督学习场景下，我们拥有一个包含 $N$ 个文档的训练集，每个文档都已由人工标注了类别：$\{(d_1,c_1),....,(d_N ,c_N )\}$。我们的目标是训练一个分类器，使其能够将新的文档 $d$ 正确地映射到其所属类别 $c \in C$，其中 $C$ 是一组有意义的文档类别集合。**概率型分类器（probabilistic classifier）** 还能告诉我们观测样本属于某个类别的概率。这种关于类别的完整概率分布对于下游决策非常有用；在系统集成时，避免过早做出硬性分类决定通常是有益的。

有许多不同类型的机器学习算法可用于构建分类器。本章介绍朴素贝叶斯；下一章将介绍逻辑回归。这两者代表了两种不同的分类方式。像朴素贝叶斯这样的**生成式（generative）分类器**会为每个类别建立一个模型，描述该类别是如何生成输入数据的。当给定一个观测样本时，它会返回最有可能生成该样本的类别。而像逻辑回归这样的**判别式（discriminative）分类器**则直接学习输入特征中哪些最有助于区分不同类别。尽管判别式系统通常更准确，因而也更常用，但生成式分类器仍然有其重要地位。
