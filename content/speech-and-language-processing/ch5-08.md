---
title: "5.8 偏见与嵌入"
summary: ""
date: 2025-12-24T09:41:00+08:00
---

除了能从文本中学习词义，嵌入——遗憾的是——也会复现文本中隐含的偏见与刻板印象。

前一节提到，嵌入能粗略建模关系相似性：例如，“king” – “man” + “woman” 的结果最接近 “queen”，这对应类比 *man:woman::king:queen*。
但同样的嵌入类比也暴露出性别刻板印象。
例如，Bolukbasi 等人（2016）发现，在基于新闻文本训练的 word2vec 嵌入中，“computer programmer” – “man” + “woman” 的最近职业词是 **“homemaker”**（家庭主妇）；
嵌入还暗示了这样的类比：“father” 之于 “doctor”，正如 “mother” 之于 “nurse”。
这类问题可能导致 Crawford（2017）和 Blodgett 等人（2020）所说的 **分配性伤害**（allocational harm），即系统在分配资源（如工作机会或信用）时，对不同群体产生不公平结果。
例如，若招聘算法使用嵌入来筛选潜在程序员或医生，就可能错误地降低包含女性姓名的文档的权重。

更严重的是，嵌入不仅反映输入文本的统计特性，还会**放大偏见**：性别相关词汇在嵌入空间中变得比原始文本中更具性别倾向（Zhao et al., 2017；Ethayarajh et al., 2019b；Jia et al., 2020），这种偏见甚至比现实劳动力就业统计数据中的偏见更为夸张（Garg et al., 2018）。

嵌入还编码了人类推理中固有的**内隐联想**（implicit associations）。
**内隐联想测验**（Implicit Association Test, IAT）通过测量人们对不同类别词汇的反应延迟，来评估其概念（如 “flowers” 或 “insects”）与属性（如 “pleasantness” 和 “unpleasantness”）之间的关联强度。[^3]
研究发现，美国人在内隐联想中表现出以下倾向：
将非裔美国人姓名与不愉快词汇的关联强于欧裔美国人姓名；
研究中发现，美国人将非裔美国人姓名与不愉快词汇的关联强于欧裔美国人姓名；
将男性姓名更多地与数学联系在一起，而将女性姓名更多地与艺术联系在一起；
并将老年人姓名与不愉快词汇相关联（Greenwald et al., 1998；Nosek et al., 2002a, 2002b）。
Caliskan 等人（2017）使用 GloVe 向量和余弦相似度（而非人类反应时间），成功复现了上述所有内隐联想结果。
例如，非裔美国人姓名（如 *Leroy*、*Shaniqua*）与不愉快词的 GloVe 余弦值更高，而欧裔美国人姓名（如 *Brad*、*Greg*、*Courtney*）则与愉快词的余弦值更高。
这类嵌入问题属于 Crawford（2017）和 Blodgett 等人（2020）定义的 **表征性伤害**（representational harm）—— 即系统通过贬低或忽视某些社会群体而造成的伤害。
因此，任何依赖词情感信息的嵌入感知算法，都可能加剧对非裔美国人的偏见。

[^3]: 简单来说，如果人们将 “flowers” 与 “pleasantness”、将 “insects” 与 “unpleasantness” 关联，那么当要求他们对 “flowers”（如 daisy, iris, lilac）和 “pleasant words”（如 love, laughter, pleasure）按绿色按钮，对 “insects”（如 flea, spider, mosquito）和 “unpleasant words”（如 abuse, hatred, ugly）按红色按钮时，  
他们的反应速度会快于不一致条件（即 green 按钮对应 insects + pleasant words，red 按钮对应 flowers + unpleasant words）。

近期研究聚焦于如何**减轻此类偏见**，例如通过对嵌入空间进行变换，在去除性别刻板印象的同时保留定义性性别差异（如 queen/king）（Bolukbasi et al., 2016；Zhao et al., 2017），或修改训练过程本身（Zhao et al., 2018b）。
然而，尽管这些 **去偏**（debiasing）方法能在一定程度上减少嵌入中的偏见，但无法完全消除它（Gonen & Goldberg, 2019）。 这仍然是一个开放性问题。

历史嵌入也被用于测量过去的偏见。
Garg 等人（2018）利用历史文本训练的嵌入，分析了 20 世纪各年代中职业词（如 “librarian”、“carpenter”）与不同族裔或性别姓名之间的关联强度（例如，女性姓名 vs. 男性姓名与这些职业词的相对余弦相似度）。
他们发现，这些余弦值与历史上各职业中女性或少数族裔的实际占比高度相关；
历史嵌入还能复现早期的种族刻板印象调查：1933 年实验参与者倾向于将 “industrious”（勤劳）、“superstitious”（迷信）等形容词与华人关联，这一倾向与基于 1930 年代文本训练的嵌入中，华人姓氏与这些形容词的余弦值显著相关。
此外，嵌入还记录了历史上的性别偏见，与能力相关的形容词（如 *smart*、*wise*、*thoughtful*、*resourceful*）与男性词的余弦值始终高于女性词；并且自 1960 年以来，这种偏见缓慢减弱。
关于偏见在自然语言处理中的作用，我们将在后续章节中再次讨论这一问题。


<nav class="pagination justify-content-between">
<a href="../ch5-07">5.7 嵌入向量的语义特性</a>
<a href="../">目录</a>
<a href="../ch5-09">5.9 向量模型的评估</a>
</nav>

