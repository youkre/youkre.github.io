---
title: "5.9 模型的解释"
summary: ""
date: 2025-10-10T08:46:00.000Z
---

我们常常希望了解的不仅仅是对某个观测样本的正确分类结果。还想知道分类器为何做出这样的决策。也就是说，我们希望决策是**可解释的**（interpretable）。可解释性很难严格定义，但其核心思想是：作为人类，我该能够理解算法为何得出某个结论。由于逻辑回归所使用的特征通常是人为设计的，因此理解分类器决策的一种方式就是弄清楚每个特征在决策中所起的作用。逻辑回归可以结合统计检验方法（如似然比检验或沃尔德检验）使用；通过这些检验来判断某个特定特征是否显著，或者检查其权重大小（该特征对应的权重 $w$ 有多大？），都有助于解释分类器做出某一决策的原因。这对于构建透明的模型至关重要。

此外，除了作为分类器使用之外，逻辑回归在自然语言处理（NLP）以及许多其他领域还被广泛用作分析工具，用于检验关于各种解释性变量（即特征）影响的假设。在文本分类中，我们可能想知道逻辑上的否定词（如 *no*、*not*、*never*）是否更可能与负面情感相关联，或者负面影评是否更倾向于讨论电影的摄影技术。然而，在进行此类分析时，必须控制潜在的混杂因素（confounds）：即其他可能影响情感的因素（如电影类型、上映年份，或影评的字数）。或者，我们可能在研究由NLP提取的语言学特征与非语言学结果（如医院再入院率、政治结果或产品销量）之间的关系，但需要控制混杂因素（如患者年龄、投票所在县、产品品牌）。在这种情况下，逻辑回归使我们能够检验某个特征是否在排除了其他特征影响的前提下，仍与某一结果存在关联。


<nav class="pagination justify-content-between">
<a href="../ch5-08">5.8 多项逻辑回归中的学习</a>
<a href="../">目录</a>
<a href="../ch5-10">5.10 进阶：梯度公式的推导</a>
</nav>

