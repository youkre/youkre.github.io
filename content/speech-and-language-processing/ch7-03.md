---
title: "7.3 提示"
summary: ""
date: 2025-12-26T21:03:00+08:00
---

这种基于上下文的生成思路本身已经非常强大，而当语言模型经过专门训练以回答问题和遵循指令后，其能力会进一步提升。
这种额外的训练称为**指令微调**（instruction-tuning）。
在指令微调中，我们从一个已通过词预测任务预训练好的基础语言模型出发，继续在一组特殊数据集上进行训练。该数据集由指令及其对应的正确构成。
数据集包含大量样本，如问题与答案、命令与执行结果，以及其他对话交互的示例。
我们将在第9章详细讨论指令微调的具体方法。

经过指令微调的语言模型非常擅长遵循指令、回答问题以及进行对话，因此可以被有效**提示**（prompted）。
所谓**提示**（prompt），是指用户向语言模型输入的一段文本，用以引导模型完成某项有用的任务。
在提示过程中，用户的提示文本被传入语言模型，模型则以此为条件，逐个生成后续词元。
为特定任务设计高效提示的过程，被称为**提示工程**（prompt engineering）。

正如我们在介绍条件生成时所提到的，提示可以是一个问题（例如 `What is a transformer network?`），也可以采用结构化格式（例如 `Q: What is a transformer network? A: `）。  
提示也可以是一条明确的指令（例如 `Translate the following sentence into Hindi: ‘Chop the garlic finely’`）。

更明确地限定可能答案范围的提示，通常能带来更好的性能。
例如，以下是一个用于情感分析的提示模板，它预先规定了可能的答案选项：

> A prompt consisting of a review plus an incomplete statement
>
> Human: Do you think that “input” has negative or positive sentiment?  
> Choices:  
> (P) Positive.  
> (N) Negative.  
>
> Assistant: I believe the best answer is: (

这个提示运用了若干更高级的提示设计技巧。
它明确限定了两个可选答案（P）和（N），并在末尾以一个左括号 `(` 结尾，强烈暗示答案将是 (P) 或 (N)。
此外，该提示还指定了语言模型的角色是“助手”。

在提示中加入一些带标签的示例也能提升模型表现。
这类示例被称为**演示**（demonstrations）。
使用示例进行提示的方法有时称为**少样本提示**（few-shot prompting），以区别于**零样本提示**（zero-shot prompting），后者指不包含任何标注示例的指令。
例如，图 7.6 展示了一个包含两个演示示例的问题，因此属于两样本提示（2-shot prompting）。
该示例来自 MMLU 数据集中的计算机科学题目（见第 7.6 节），MMLU 常被用于评估语言模型。

> Example of demonstrations in a computer science question from the MMLU dataset described in Section
>
> The following are multiple choice questions about high school computer science.
>
> Let x = 1. What is x <<3 in Python 3?  
> (A) 1 (B) 3 (C) 8 (D) 16  
> Answer: C.
>
> Which is the largest asymptotically?  
> (A) O(1) (B) O(n) (C) O(n2) (D) O(log(n))  
> Answer: C
>
> What is the output of the statement “a” + “ab” in Python 3?  
> (A) Error (B) aab (C) ab (D) a ab  
> Answer:

**图 7.6** 来自 MMLU 的高中计算机科学测试题的两样本提示示例。（正确答案为 (B)）

这些演示通常从带标签的训练集中选取。
可以人工挑选，也可以借助优化器（如 DSPy，Khattab 等，2024）自动选择一组能在开发集上最大程度提升任务性能的演示。
演示数量无需太多：更多示例带来的收益会逐渐递减，而示例过多甚至可能导致模型过度拟合到具体例子本身。
演示的主要作用似乎并非提供特定问题的正确答案，而是向模型展示任务目标和输出格式。
事实上，即使演示中的答案是错误的，仍可能提升系统性能（Min 等，2022；Webson 和 Pavlick，2022）。

提示不仅是一种引导语言模型生成文本的方式，也可被视为一种**学习信号**。
这一点在包含演示的提示中尤为明显：这些示例能帮助语言模型从新任务的样例中学会如何执行该任务。  
这种学习方式不同于我们将在下文描述的、通过梯度下降更新模型权重的预训练方法。
提示不会改变模型的参数权重；它改变的只是输入上下文以及网络内部的激活状态。

因此，我们将提示过程中发生的这种学习称为**上下文内学习**（in-context learning）——即一种能提升模型性能或降低某种损失，但不涉及对模型底层参数进行梯度更新的学习形式。

大语言模型通常还配备一个**系统提示**（system prompt）：这是一段固定的文本提示，作为模型接收的第一条指令，用于定义模型的任务或角色，并设定整体语气与上下文。
系统提示会被静默地添加到用户输入之前。
例如，以下是一个最简化的系统提示，用于构建多轮对话助手，其中包含了一些特殊的元标记（metatokens）：

> &lt;system&gt;You are a helpful and knowledgeable assistant. Answer
> concisely and correctly.

因此，如果用户想知道法国的首都是什么，实际用作语言模型条件生成上下文的完整文本是：

> &lt;system&gt; You are a helpful and knowledgeable assistant.
> Answer concisely and correctly.  
> &lt;user&gt; What is the capital of France?

现代语言模型支持极长的上下文（可达数万个词元），这使其在条件生成任务中极为强大，因为它们可以回溯非常远的提示文本。
这意味着系统提示以及各类提示本身都可以非常长。

例如，Anthropic 公司的 Claude Opus4 模型所使用的完整系统提示长达 1700 个单词，其中包含如下内容：

> Claude should give concise responses to very simple questions, but provide thorough responses to complex and open-ended questions.  
> Claude is able to explain difficult concepts or ideas clearly. It can also illustrate its explanations with examples, thought experiments, or metaphors.  
> Claude does not provide information that could be used to make chemical or biological or nuclear weapons  
> For more casual, emotional, empathetic, or advice-driven conversations, Claude keeps its tone natural, warm, and empathetic  
> Claude cares about people’s well-being and avoids encouraging or facilitating self-destructive behavior  
> If Claude provides bullet points in its response, it should use markdown, and each bullet point should be at least 1-2 sentences long unless the human requests otherwise

我们也可以为其他任务设计系统提示。例如，以下是一个用于构建通用语法检查器的系统提示（Anthropic, 2025）：

> Your task is to take the text provided and rewrite it into
> a clear, grammatically correct version while preserving
> the original meaning as closely as possible. Correct any
> spelling mistakes, punctuation errors, verb tense issues,
> word choice problems, and other grammatical mistakes.

之后，每位用户只需提供一段具体文本作为提示，系统便会自动修正其语法错误。

在所有这些情况下，系统提示都会被前置到用户的任何提示或查询之前，整个拼接后的字符串将作为语言模型进行条件生成的完整上下文。


<nav class="pagination justify-content-between">
<a href="../ch7-02">7.2 文本的条件生成：基本原理</a>
<a href="../">目录</a>
<a href="../ch7-04">7.4 生成与采样</a>
</nav>

