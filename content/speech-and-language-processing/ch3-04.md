---
title: "3.4 从语言模型中采样句子"
summary: ""
date: 2025-07-20T11:50:38+08:00
---

<figure>

![](/images/speech-and-language-processing/slp-fig-3-3.png)

<figcaption>

<span>图 3.3</span> 展示了通过不断采样一元语法（unigram）来生成句子时的采样分布。蓝色条形图表示每个词的相对频率（按从高频到低频的顺序排列，但顺序本身是任意的）。数轴显示了累积概率。如果随机选择一个介于 0 和 1 之间的数字，它会落在某个词所对应的区间内。我们更有可能随机选中高频词（如 *the*、*of*、*a*）所对应的较大区间，而不太可能选中低频词（如 *polyphonic*）所对应的小区间。

</figcaption>
</figure>

可视化语言模型所包含知识的一种重要方式是**从模型中采样**。所谓从一个分布中采样，就是按照每个结果出现的可能性大小来随机选择结果。因此，从语言模型中采样——该模型本质上是对句子分布的一种表示——意味着生成一些句子，每个句子的生成概率由模型定义的概率决定。也就是说，我们更容易生成模型认为概率较高的句子，而更难生成模型认为概率较低的句子。

通过采样来可视化语言模型的思想最早由 Shannon（1948）以及 Miller 和 Selfridge（1950）提出。我们可以先从一元语法模型入手，来理解这个过程。想象英语中的所有词排列在 0 到 1 的数轴上，每个词占据的区间长度与其出现频率成正比。图 3.3 展示了一个可视化示例，它使用的是根据本书文本训练出的一元语言模型。我们随机选择一个介于 0 和 1 之间的数值，在概率线上找到对应的位置，输出该数值落在哪个词的区间内。不断重复这个过程生成词，直到随机生成句子结束标记 `</s>`，此时句子生成结束。

也可以用同样的方法生成二元语法（bigram）句子。首先根据起始标记 `<s>` 出现的所有二元组的概率，随机选择一个以 `<s>` 开头的二元组。假设选中的二元组的第二个词是 *w*，那么下一步就根据以 *w* 开头的所有二元组的概率，再次随机选择下一个词，依此类推，直到生成句子结束标记 `</s>` 为止。


<nav class="pagination justify-content-between">
<a href="../ch3-03">3.3 评估语言模型：困惑度（Perplexity）</a>
<a href="../">目录</a>
<a href="../ch3-05">3.5 对训练集的泛化与过拟合</a>
</nav>

