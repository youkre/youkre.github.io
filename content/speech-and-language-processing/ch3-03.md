---
title: "3.3 评估语言模型：困惑度（Perplexity）"
summary: ""
date: 2025-07-20T09:47:38+08:00
---

我们前面提到，评估语言模型的方法是看哪个模型为测试集分配了更高的概率。一个更优的语言模型在预测下一个词方面表现得更好，因此在测试集中遇到每个词时会“更不惊讶”（即分配更高的概率）。事实上，一个完美的语言模型能够准确预测语料中的每一个下一个词，将其概率设为1，而所有其他词的概率为0。因此，给定一个测试语料库，更好的语言模型会比较差的模型分配更高的整体概率。

然而，实际上我们并不直接使用原始概率作为评估语言模型的指标。原因在于，测试集（或任何序列）的概率依赖于其中的词数或词符（token）数量；文本越长，测试集的概率就越小。我们更希望使用一个**以词为单位**、**按长度归一化**的指标，这样就可以在不同长度的文本之间进行比较。我们使用的这个指标是一种基于概率的函数，称为**困惑度**（perplexity），它是自然语言处理中最重要的评估指标之一，既用于评估大型语言模型，也用于评估n元语法模型。

某个测试集上语言模型的**困惑度**（有时缩写为PP或PPL），是指测试集概率的倒数（即1除以测试集的概率），并按词数进行归一化。正因如此，它有时也被称为**每词困惑度**或**每词符困惑度**。我们通过取N次方根来对词数N进行归一化。对于一个测试集 $ W = w_1 w_2 ... w_N $，其困惑度定义如下：

$$
\begin{aligned}
\text{perplexity}(W) &= P(w_1w_2 ... w_N )^{-\frac{1}{N}} \\
&= \sqrt[N]{\frac{1}{P(w_1w_2 ... w_N )}}
\end{aligned}
$$

(3.14)
{class="text-end"}

或者，也可以利用链式法则展开 $W$ 的概率：

$$
\text{perplexity}(W) = \sqrt[N]{\prod_{i=1}^{N} \frac{1}{P(w_i | w_1 ... w_{i-1})}}
$$

(3.15)
{class="text-end"}

需要注意的是，由于公式（3.15）中使用了倒数，词序列的概率越高，困惑度就越低。因此，**语言模型在数据上的困惑度越低，模型表现越好**。最小化困惑度等价于根据语言模型最大化测试集的概率。为什么困惑度要使用概率的倒数呢？实际上，这个倒数来源于信息论中交叉熵率的原始定义。对于有兴趣的读者，详细解释可以在进阶章节3.7中找到。目前，我们只需要记住：**困惑度与概率成反比**。

计算测试集 $ W $ 的困惑度的具体细节取决于我们使用的语言模型类型。下面以一个一元语法（unigram）语言模型为例，其测试集 $ W $ 的困惑度定义如下（即所有词的一元概率倒数的几何平均）：

$$
\text{perplexity}(W) = \sqrt[N]{\prod_{i=1}^{N}\frac{1}{P(w_i)}}
$$

(3.16)
{class="text-end"}

如果使用二元语法（bigram）语言模型来计算测试集 $ W $ 的困惑度，它依然是一个几何平均值，但这次是基于二元概率的倒数：

$$
\text{perplexity}(W) = \sqrt[N]{\prod_{i=1}^{N}\frac{1}{P(w_i|w_{i-1})}}
$$

(3.17)
{class="text-end"}

在公式（3.15）或（3.17）中，我们通常使用的词序列是指某个测试集中完整的词序列。由于这个序列可能跨越多个句子边界，如果词汇表中包含表示句子结束的标记 `<EOS>` 或者有明确的起始与结束标记 `<s>` 和 `</s>`，那么可以在概率计算中将这些标记一并考虑进去。如果这样做，那么在总词数 $ N $ 中，每个句子还会额外计入一个标记。

前面提到，困惑度是测试文本和语言模型两者的函数：对于同一段文本 $ W $，不同的语言模型会产生不同的困惑度。正因为如此，困惑度可以用于比较不同语言模型的表现。例如，我们在《华尔街日报》的3800万词语料上训练了一元、二元和三元语法模型，然后分别使用公式（3.16）计算一元模型、公式（3.17）计算二元模型，以及对应的三元模型公式，来评估它们在一个150万词的测试集上的困惑度。结果如下表所示：

|       | 一元模型（Unigram） | 二元模型（Bigram） | 三元模型（Trigram） |
| ----- | ------------------- | ------------------ | ------------------- |
| 困惑度（Perplexity） | 962               | 170              | 109               |

如上表所示，n元语法模型提供的关于词序列的信息越多，该模型对词序列所分配的概率就越高。三元模型比一元模型更“不惊讶”，因为它对下一个可能出现的词有更好的预测能力，因此为这些词分配了更高的概率。而概率越高，困惑度就越低（正如公式3.15所示，困惑度与模型对测试序列的概率成反比）。因此，**更低的困惑度意味着语言模型对测试集的预测能力更强**。

需要注意的是，在计算困惑度时，语言模型的构建不能包含任何测试集的信息，否则会导致困惑度被人为地压低。此外，只有在两个语言模型使用**完全相同的词汇表**的情况下，它们的困惑度才具有可比性。

尽管如此，**内在评估指标**（如困惑度）的提升**并不能保证**在语音识别或机器翻译等**外在任务**中也会有相应的提升。然而，由于困惑度通常与任务性能的提升具有一定的相关性，因此它仍然是一个被广泛使用的便捷评估指标。即便如此，当条件允许时，模型在困惑度上的改进仍应通过在真实任务上的端到端评估来加以验证。

### 3.3.1 作为加权平均分支因子的困惑度

事实上，**困惑度也可以理解为语言的加权平均分支因子**（weighted average branching factor）。所谓语言的分支因子，是指在任意一个词之后可能出现的不同词的数量。

举个例子，假设我们有一个小型的人造语言 $ L $，它是确定性的（没有概率），任何词都可以跟在另一个词之后，并且词汇表只包含三种颜色：

$$
L = \{\texttt{red}, \texttt{blue}, \texttt{green}\}
$$

(3.18)
{class="text-end"}

这个语言的分支因子是 3，因为每个词后面都可以跟任意一个词，共有 3 种可能。

现在，我们把这个语言模型变成一个概率版本的模型，称之为 $A$，其中每个词以相等的概率 $\frac{1}{3}$ 跟在其他词之后（也就是说它是在一个三种颜色出现次数相等的训练集上训练出来的）。我们给定一个测试集 `T = “red red red red blue”`。

可以先验证一下，在这个测试集（或任何类似的测试集）上计算出的人造语言困惑度是否真的是 3。根据公式（3.15）：

$$
\begin{aligned}
\text{perplexity}_A(T) &= P_A(\texttt{red}\ \texttt{red}\ \texttt{red}\ \texttt{red}\ \texttt{blue})^{-\frac{1}{5}} \\
&= \left( \left( \frac{1}{3} \right)^5 \right)^{-\frac{1}{5}} \\
&= \left( \frac{1}{3} \right)^{-1} \\
&= 3
\end{aligned}
$$

(3.19)
{class="text-end"}

现在再考虑另一个语言模型 B，它是在一个不同训练集上训练出来的，其中 `red` 出现得非常频繁。因此模型 B 的词概率如下：

$$
\begin{aligned}
P(\texttt{red}) &= 0.8 \\
P(\texttt{green}) &= 0.1 \\
P(\texttt{blue}) &= 0.1
\end{aligned}
$$

(3.20)
{class="text-end"}

我们可以预期，对于相同的测试集 `red red red red blue`，模型 B 的困惑度会更低，因为大多数情况下下一个词是“red”，这非常容易预测，即它的概率很高。因此整个测试集的概率更高，而由于困惑度与概率成反比，所以它的困惑度会更低。虽然语言的分支因子仍然是 3，但困惑度（即加权平均分支因子）却更小了：

$$
\begin{aligned}
\text{perplexity}_B(T) &= P_B(\texttt{red}\ \texttt{red}\ \texttt{red}\ \texttt{red}\ \texttt{blue})^{-\frac{1}{5}} \\
&= 0.04096^{-\frac{1}{5}} \\
&= 0.527^{-1} \\
&= 1.89
\end{aligned}
$$

(3.21)
{class="text-end"}

这个例子说明，困惑度不仅反映了语言中可能的词数（分支因子），还考虑了这些词出现的概率分布。当某些词更可预测时，模型的困惑度会下降，说明它对语言的建模更准确。


<nav class="pagination justify-content-between">
<a href="../ch3-02">3.2 评估语言模型：训练集与测试集</a>
<a href="../">目录</a>
<a href="../ch3-04">3.4 从语言模型中采样句子</a>
</nav>

