---
title: "12.7 偏见与伦理问题"
summary: ""
date: 2025-12-31T03:58:00+08:00
---

机器翻译引发了我们在前几章中讨论过的许多相同伦理问题。
例如，考虑从匈牙利语（使用性别中立的代词 ő）或西班牙语（常常省略代词）翻译成英语（代词为语法强制项，且具有语法性别）的情况。
当源文中提到某个人但未指明性别时，机器翻译系统往往会默认使用男性代词（Schiebinger, 2014；Prates et al., 2019）。
此外，MT 系统还常常依据我们在第 5.8 节中看到的那种文化刻板印象来分配性别。
图 12.12 展示了 Prates et al.（2019）的研究案例：匈牙利语中 *ő is a nurse* 的 ő 是性别中立的，英语翻译为 *she*，在 *ő is a CEO* 中同样是中立的，却被译为 *he*。
Prates 等人发现，这些偏见无法完全用美国劳动力中的性别统计数据解释，因为 MT 系统实际上放大了这些偏见——其将中性代词映射为男性或女性的概率，高于仅基于实际就业统计数据所应得出的概率。

| 匈牙利语（性别中立）原文 | 英语机器翻译输出 |
| --- | --- |
| ő egy ápoló | she is a nurse |
| ő egy tudós | he is a scientist |
| ő egy mérnök | he is an engineer |
| ő egy pék | he is a baker |
| ő egy tanár | she is a teacher |
| ő egy esküvőszervező | she is a wedding organizer |
| ő egy vezérigazgató | he is a CEO |

**图 12.12** 当从匈牙利语等性别中立语言翻译成英语时，当前的 MT 系统会将传统上由男性主导职业的人解读为男性，而将传统上由女性主导职业的人解读为女性（Prates et al., 2019）。

类似地，近期提出的挑战集 WinoMT 数据集（Stanovsky et al., 2019）表明，当要求 MT 系统翻译描述非刻板性别角色的句子时（例如：“The doctor asked the nurse to help her in the operation”——医生请护士在手术中帮助她），其表现明显更差。

机器翻译中的许多伦理问题仍需深入研究。一个尚未解决的关键问题是：如何开发衡量“系统不知道什么”的指标。
这是因为 MT 系统常被用于紧急场景——在这些场景中，人工译员可能无法及时提供服务，例如在医疗领域帮助患者与不会说同一种语言的医生沟通；在法律领域协助法官或律师与证人或被告交流。
为了践行“不造成伤害”（do no harm）的原则，系统需要能够为候选译文分配置信度（confidence）值，从而在不确定性较高时主动拒绝输出可能有害的错误翻译。


<nav class="pagination justify-content-between">
<a href="../ch12-06">12.6 机器翻译评估</a>
<a href="../">目录</a>
<a href="../ch13">第 13 章 循环神经网络与长短期记忆网络</a>
</nav>

