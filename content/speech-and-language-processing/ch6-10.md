---
title: "6.10 嵌入向量的语义特性"
summary: ""
date: 
---

本节简要总结一些已被研究过的嵌入向量的语义特性。

**不同类型的相似性或关联性**：对于稀疏的 tf-idf 向量和稠密的 word2vec 向量而言，矢量语义模型中一个共同相关的参数是用于统计共现次数的上下文窗口大小。
通常，该窗口在目标词左右各取 1 到 10 个词（总上下文长度为 2–20 个词）。

具体选择取决于表示的目标。较短的上下文窗口倾向于产生更具句法性质的表示，因为信息来自紧邻的词语。
当使用短上下文窗口计算向量时，与目标词 *w* 最相似的词通常是具有相同词性、语义相近的词；而当使用长上下文窗口计算向量时，与目标词 *w* 余弦相似度最高的词往往是主题相关但并不语义相似的词。

例如，Levy 和 Goldberg (2014a) 指出，在使用 ±2 窗口的跳字模型中，与 *Hogwarts*（《哈利·波特》中的霍格沃茨魔法学校）最相似的词是其他虚构学校的名称，如 *Sunnydale*（出自《吸血鬼猎人巴菲》）或 *Evernight*（出自某吸血鬼系列）。
而当窗口扩大到 ±5 时，与 *Hogwarts* 最相似的词则变为《哈利·波特》系列中的主题相关词，如 *Dumbledore*（邓布利多）、*Malfoy*（马尔福）和 *half-blood*（混血）。

此外，通常还需区分两种词间相似性或关联性（Schütze 和 Pedersen, 1993）。
如果两个词经常彼此相邻出现，则它们具有**一阶共现关系**（有时称为**组合型关联**，syntagmatic association）。例如，*wrote*（写）是一阶关联词，常出现在 *book*（书）或 *poem*（诗）附近。
如果两个词拥有相似的上下文邻居，则它们具有**二阶共现关系**（有时称为**聚合型关联**，paradigmatic association）。例如，*wrote* 与 *said*（说）或 *remarked*（评论）属于二阶关联词，因为它们在语言中扮演相似的角色。

**类比/关系相似性**：嵌入向量的另一重要语义特性是其捕捉关系意义的能力。
在早期关于认知的向量空间模型中，Rumelhart 和 Abrahamson (1973) 提出了**平行四边形模型**（parallelogram model），用于解决形式为“*a 对 b 如同 a\* 对什么？*”的简单类比问题。
例如，给定问题 *apple:tree::grape:?*（即“苹果之于树，如同葡萄之于__”），系统需填入 *vine*（藤蔓）。如图 6.15 所示，在平行四边形模型中，从 *apple* 到 *tree* 的向量（即 $\overrightarrow{tree} - \overrightarrow{apple}$）被加到 *grape* 的向量（$\overrightarrow{grape}$）上，然后找出离该点最近的词作为答案。

早期基于稀疏嵌入的研究已表明，稀疏向量语义模型可以解决此类类比问题（Turney 和 Littman, 2005）。
但近年来，由于 word2vec 和 GloVe 等稠密嵌入在此任务上的显著成功，平行四边形方法重新受到广泛关注（Mikolov 等, 2013c；Levy 和 Goldberg, 2014b；Pennington 等, 2014）。
例如，表达式 $\overrightarrow{king} - \overrightarrow{man} + \overrightarrow{woman}$ 所得向量接近于 $\overrightarrow{queen}$；类似地，$\overrightarrow{Paris} - \overrightarrow{France} + \overrightarrow{Italy}$ 的结果向量接近于 $\overrightarrow{Rome}$。
这表明嵌入模型似乎能够提取诸如 **男性–女性**、**首都–所属国家**，甚至**比较级/最高级**等关系的表示，如图 6.16 中 GloVe 向量空间所示。

**图 6.15** 类比问题的平行四边形模型（Rumelhart 和 Abrahamson, 1973）：通过计算 $\overrightarrow{tree} - \overrightarrow{apple} + \overrightarrow{grape}$ 可定位到 $\overrightarrow{vine}$ 的位置。

**图 6.16** GloVe 向量空间的关系特性（投影至二维展示）：(a) $\overrightarrow{king} - \overrightarrow{man} + \overrightarrow{woman}$ 接近 $\overrightarrow{queen}$；(b) 向量偏移似乎能捕捉形容词的比较级与最高级形态变化（Pennington 等, 2014）。

对于一个 $a : b :: a^* : b^*$ 类比问题（即算法已知向量 **a**, **b**, $a^*$，需找出 $b^*$），平行四边形方法可形式化为：

$$
\hat{b^*}= \argmin_x \text{distance}(x, \mathbf{b} - \mathbf{a} + \mathbf{a^*})
\tag{6.41}
$$

其中 distance 可以是欧氏距离等距离函数。

不过需要注意几点限制。例如，在 word2vec 或 GloVe 嵌入空间中，平行四边形算法返回的最近邻通常并非真正的 $b^*$，而是三个输入词之一或其形态变体（例如，“*cherry:red :: potato:x*” 返回的是 *potato* 或 *potatoes*，而非 *brown*），因此必须显式排除这些候选。
此外，尽管嵌入空间在处理高频词、小距离以及特定关系（如国家与其首都、动词/名词与其屈折形式）时表现良好，但对于其他类型的关系，平行四边形方法效果较差（Linzen, 2016；Gladkova 等, 2016；Schluter, 2018；Ethayarajh 等, 2019a）。
事实上，Peterson 等 (2020) 认为，平行四边形模型整体上过于简化，无法充分刻画人类形成此类类比的认知过程。

### 6.10.1 嵌入与历史语义学

嵌入还可用于研究词义如何随时间演变：通过为不同历史时期的文本分别构建多个嵌入空间，即可追踪语义变迁。例如，图 6.17 展示了过去两个世纪英语词汇语义变化的可视化结果，这些结果是基于 Google n-grams 和《美国英语历史语料库》（Corpus of Historical American English, Davies, 2012）等历史语料，按十年为单位分别训练 word2vec 嵌入后得到的（Lin 等, 2012b）。

**图 6.17** 使用 word2vec 向量对三个英语词进行语义演变的 t-SNE 可视化。现代词义及灰色上下文词由最新（现代）时间段的嵌入空间计算得出，早期点则来自更早的历史嵌入空间。图中展示了 *gay* 一词从“愉快”或“嬉戏”的含义逐渐转向指代“同性恋”；*broadcast* 从最初“播撒种子”的含义发展出如今“广播/传播”的现代用法；*awful* 一词经历了贬义化（pejoration），从原意“充满敬畏”转变为“糟糕或可怕”（Hamilton 等, 2016b）。


<nav class="pagination justify-content-between">
<a href="../ch6-09">6.9 嵌入向量的可视化</a>
<a href="../">目录</a>
<a href="../ch6-11">6.11 嵌入中的偏见</a>
</nav>

